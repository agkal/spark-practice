{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#week-2 Abdul Ghaffar Assignment-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTable(tableName):\n",
    "    \"\"\" Used to built connection with database and read table data \n",
    "    Args:\n",
    "        tableName (str): table name to read data from\n",
    "    Returns:\n",
    "        dataframe_mysql: mysql dataframe\n",
    "    \"\"\"\n",
    "    dataframe_mysql = spark.read.format(\"jdbc\").options(\n",
    "        url=\"jdbc:mysql://localhost:3306/pyspark\",\n",
    "        driver = \"com.mysql.jdbc.Driver\",\n",
    "        dbtable = tableName,\n",
    "        user=\"ghaffar\",\n",
    "        password=\"1234\").load()\n",
    "    return dataframe_mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling function readTable to read data from the databases\n",
    "studentTable = readTable('student')\n",
    "courseTable = readTable('course')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------+\n",
      "| id|         name|college|\n",
      "+---+-------------+-------+\n",
      "|  1|Abdul Ghaffar|   NUST|\n",
      "+---+-------------+-------+\n",
      "\n",
      "+---+------------+----------+\n",
      "| id|        name|student_id|\n",
      "+---+------------+----------+\n",
      "| 22|Apache Spark|         1|\n",
      "+---+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show table dataframe values\n",
    "studentTable.show()\n",
    "courseTable.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------+\n",
      "| id|         name|college|\n",
      "+---+-------------+-------+\n",
      "|  1|Abdul Ghaffar|   NUST|\n",
      "+---+-------------+-------+\n",
      "\n",
      "+---+------------+----------+\n",
      "| id|        name|student_id|\n",
      "+---+------------+----------+\n",
      "| 22|Apache Spark|         1|\n",
      "+---+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create temperory view for the give tables to perform sql operations\n",
    "studentTable.createOrReplaceTempView(\"students\")\n",
    "studentView = spark.sql(\"SELECT * FROM students\")\n",
    "studentView.show()\n",
    "\n",
    "courseTable.createOrReplaceTempView(\"courses\")\n",
    "courseView = spark.sql(\"SELECT * FROM courses\")\n",
    "courseView.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply join operation of these two created tables\n",
    "student_course_join = spark.sql(\"select students.id as std_id, students.name as std_name, courses.id as course_id, courses.name as course_name  from students join courses on students.id = courses.student_id;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---------+------------+\n",
      "|std_id|     std_name|course_id| course_name|\n",
      "+------+-------------+---------+------------+\n",
      "|     1|Abdul Ghaffar|       22|Apache Spark|\n",
      "+------+-------------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show result of new joined table\n",
    "student_course_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save student_course_join table in the mysql database\n",
    "student_course_join.write.format('jdbc').options(\n",
    "      url='jdbc:mysql://localhost:3306/pyspark',\n",
    "      driver='com.mysql.jdbc.Driver',\n",
    "      dbtable='student_course_join',\n",
    "      user='ghaffar',\n",
    "      password='1234').mode('append').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---------+------------+\n",
      "|std_id|     std_name|course_id| course_name|\n",
      "+------+-------------+---------+------------+\n",
      "|     1|Abdul Ghaffar|       22|Apache Spark|\n",
      "|     1|Abdul Ghaffar|       22|Apache Spark|\n",
      "+------+-------------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read the saved table again from database\n",
    "newTable = readTable('student_course_join')\n",
    "newTable.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
