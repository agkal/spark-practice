{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Abdul Ghaffar -- Week 2 Apache Pyspark\n",
    "### Assignment 1: \n",
    "#### Write a PySpark job that \n",
    "##### 1. Takes Apache log file as input (get any Apache log file available online)\n",
    "##### 2. Parses the rows using map functions and get the result as RDD\n",
    "##### 3. Filters out the rows that do no have a URL available\n",
    "##### 4. Groups the data on IP addresses\n",
    "##### 5. Calculates the average session length against every IP address\n",
    "##### 6. Saves the output on a disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import os\n",
    "from pyspark.sql.functions import col, max as max_, min as min_\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"Read Log files\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf = conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A regular expression pattern to extract fields from the log line\n",
    "#APACHE_ACCESS_LOG_PATTERN = '^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(\\S+) (\\S+)\\s*(\\S*)\" (\\d{3}) (\\S+)'\n",
    "APACHE_ACCESS_LOG_PATTERN = '^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(\\S+) (.*?) (\\S+)\" (\\d{3}) (\\S+) \"(.*?)\" \"(.*?)\"$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "month_map = {'Jan': 1, 'Feb': 2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7,\n",
    "    'Aug':8,  'Sep': 9, 'Oct':10, 'Nov': 11, 'Dec': 12}\n",
    "\n",
    "def parse_time(s):\n",
    "    \"\"\" Used to convert Apache time format into a Python datetime object\n",
    "    Args:\n",
    "        s (str): date and time in Apache time format\n",
    "    Returns:\n",
    "        datetime: datetime object (ignore timezone for now)\n",
    "    \"\"\"\n",
    "    return datetime.datetime(int(s[7:11]),\n",
    "                             month_map[s[3:6]],\n",
    "                             int(s[0:2]),\n",
    "                             int(s[12:14]),\n",
    "                             int(s[15:17]),\n",
    "                             int(s[18:20]))\n",
    "\n",
    "\n",
    "def parseApacheLogLine(log_file_line):\n",
    "    \"\"\" Parse a line in the Apache Common Log format\n",
    "    Args:\n",
    "        log_file_line (str): a line of text in the Apache Common Log format\n",
    "    Returns:\n",
    "        tuple: either a dictionary containing the parts of the Apache Access Log and 1,\n",
    "               or the original invalid log line and 0\n",
    "    \"\"\"\n",
    "    match_result = re.search(APACHE_ACCESS_LOG_PATTERN, log_file_line)\n",
    "    if match_result is None:\n",
    "        return (log_file_line, 0)\n",
    "    size_field = match_result.group(9)\n",
    "    if size_field == '-':\n",
    "        size = 0\n",
    "    else:\n",
    "        size = match_result.group(9)\n",
    "    return (Row(\n",
    "        host_ip          = match_result.group(1),\n",
    "        client_identd = match_result.group(2),\n",
    "        user_id       = match_result.group(3),\n",
    "        date_time     = parse_time(match_result.group(4)),\n",
    "        method        = match_result.group(5),\n",
    "        endpoint      = match_result.group(6),\n",
    "        protocol      = match_result.group(7),\n",
    "        response_code = int(match_result.group(8)),\n",
    "        content_size  = size,\n",
    "        referrer     = match_result.group(10),\n",
    "        userAgent    = match_result.group(11)\n",
    "    ), 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid logline: 2\n",
      "Invalid logline: 83.149.9.216 - - [17/May/2015:10:05:03 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-search.png HTTP/1.1\" 200 203023 \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n",
      "Invalid logline: 46.118.127.106 - - [20/May/2015:12:05:17 +0000] \"GET /scripts/grok-py-test/configlib.py HTTP/1.1\" 200 235 \"-\" \"Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html\n",
      "Read 10000 lines, successfully parsed 9998 lines, failed to parse 2 lines\n"
     ]
    }
   ],
   "source": [
    "logFile = \"apache_logs.txt\"\n",
    "\n",
    "def parseLogs():\n",
    "    \"\"\" Read and parse log file \"\"\"\n",
    "    parsed_logs = (sc.textFile(logFile).map(parseApacheLogLine).cache())\n",
    "\n",
    "    access_logs = (parsed_logs\n",
    "                   .filter(lambda s: s[1] == 1)\n",
    "                   .map(lambda s: s[0])\n",
    "                   .cache())\n",
    "\n",
    "    failed_logs = (parsed_logs\n",
    "                   .filter(lambda s: s[1] == 0)\n",
    "                   .map(lambda s: s[0]))\n",
    "    failed_logs_count = failed_logs.count()\n",
    "    if failed_logs_count > 0:\n",
    "        print ('Number of invalid logline: %d' % failed_logs.count())\n",
    "        for line in failed_logs.take(20):\n",
    "            print ('Invalid logline: %s' % line)\n",
    "\n",
    "    print ('Read %d lines, successfully parsed %d lines, failed to parse %d lines' % (parsed_logs.count(), access_logs.count(), failed_logs.count()))\n",
    "    return parsed_logs, access_logs, failed_logs\n",
    "\n",
    "\n",
    "parsed_logs, access_logs, failed_logs = parseLogs()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(host_ip='83.149.9.216', client_identd='-', user_id='-', date_time=datetime.datetime(2015, 5, 17, 10, 5, 43), method='GET', endpoint='/presentations/logstash-monitorama-2013/images/kibana-dashboard3.png', protocol='HTTP/1.1', response_code=200, content_size='171717', referrer='http://semicomplete.com/presentations/logstash-monitorama-2013/', userAgent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36'), Row(host_ip='83.149.9.216', client_identd='-', user_id='-', date_time=datetime.datetime(2015, 5, 17, 10, 5, 47), method='GET', endpoint='/presentations/logstash-monitorama-2013/plugin/highlight/highlight.js', protocol='HTTP/1.1', response_code=200, content_size='26185', referrer='http://semicomplete.com/presentations/logstash-monitorama-2013/', userAgent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36')]\n"
     ]
    }
   ],
   "source": [
    "print(access_logs.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert access_logs rdd to dataframe\n",
    "access_logs_df = access_logs.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9998"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## filter empty urls with null value\n",
    "access_logs_df = access_logs_df.filter(access_logs_df.host_ip != \"\")\n",
    "access_logs_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|        host_ip|count|\n",
      "+---------------+-----+\n",
      "|  87.169.99.232|    1|\n",
      "|  99.188.185.40|    1|\n",
      "|   31.45.226.43|    1|\n",
      "|    5.39.15.151|    2|\n",
      "|  131.114.11.55|    2|\n",
      "|188.238.146.131|    1|\n",
      "| 208.43.243.244|    8|\n",
      "|    180.76.5.74|    1|\n",
      "| 203.84.135.120|    6|\n",
      "| 76.164.234.106|    2|\n",
      "| 128.179.155.97|    6|\n",
      "| 173.192.238.44|    1|\n",
      "| 86.185.215.203|    1|\n",
      "| 107.170.40.205|    4|\n",
      "|  213.180.27.58|    1|\n",
      "| 197.187.26.144|    1|\n",
      "|  173.213.76.77|    2|\n",
      "|  109.74.154.79|    7|\n",
      "|   200.10.161.5|    4|\n",
      "|    82.60.18.23|    2|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#groupBy based on ip requests made\n",
    "access_logs_df_ip_grouped = access_logs_df.groupBy('host_ip').count()\n",
    "access_logs_df_ip_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|        host_ip|average_session_time|\n",
      "+---------------+--------------------+\n",
      "|  87.169.99.232|       1.431839159E9|\n",
      "|  99.188.185.40|        1.43186071E9|\n",
      "|   31.45.226.43|       1.431889548E9|\n",
      "|    5.39.15.151|      1.4319471255E9|\n",
      "|  131.114.11.55|      1.4320317275E9|\n",
      "|188.238.146.131|       1.432119939E9|\n",
      "| 208.43.243.244|      1.4321271305E9|\n",
      "|    180.76.5.74|       1.431903959E9|\n",
      "| 203.84.135.120|1.4319471486666667E9|\n",
      "| 76.164.234.106|        1.43195431E9|\n",
      "| 128.179.155.97|1.4321043326666667E9|\n",
      "| 173.192.238.44|       1.432109148E9|\n",
      "| 86.185.215.203|       1.432116354E9|\n",
      "| 107.170.40.205|     1.43197232825E9|\n",
      "|  213.180.27.58|         1.4319831E9|\n",
      "| 197.187.26.144|       1.431997523E9|\n",
      "|  173.213.76.77|      1.4320119225E9|\n",
      "|  109.74.154.79|1.4320587325714285E9|\n",
      "|   200.10.161.5|       1.432096537E9|\n",
      "|    82.60.18.23|      1.4321163315E9|\n",
      "+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as func\n",
    "\n",
    "#average session length against every IP address\n",
    "access_logs_df_session_time = access_logs_df.groupBy('host_ip').agg(func.avg('date_time').alias('average_session_time'))\n",
    "access_logs_df_session_time.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_logs_df_session_time.coalesce(1).write.format('csv').option(\"header\", \"true\").save('access_logs_df_session_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(access_logs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find session active for urls which has been requested\n",
    "access_logs_df_gr = access_logs_df.withColumn(\"date_time\", col(\"date_time\").cast(\"timestamp\")) \\\n",
    "    .groupBy(\"host_ip\") \\\n",
    "    .agg((max_(\"date_time\") - min_(\"date_time\")).alias(\"session_length\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|        host_ip|      session_length|\n",
      "+---------------+--------------------+\n",
      "|  87.169.99.232|           0 seconds|\n",
      "|  99.188.185.40|           0 seconds|\n",
      "|   31.45.226.43|           0 seconds|\n",
      "|    5.39.15.151|           7 seconds|\n",
      "|  131.114.11.55| 31 hours 17 seconds|\n",
      "|188.238.146.131|           0 seconds|\n",
      "| 208.43.243.244|          53 seconds|\n",
      "|    180.76.5.74|           0 seconds|\n",
      "| 203.84.135.120|          26 seconds|\n",
      "| 76.164.234.106|          10 seconds|\n",
      "| 128.179.155.97|  2 hours 30 seconds|\n",
      "| 173.192.238.44|           0 seconds|\n",
      "| 86.185.215.203|           0 seconds|\n",
      "| 107.170.40.205|69 hours 59 minut...|\n",
      "|  213.180.27.58|           0 seconds|\n",
      "| 197.187.26.144|           0 seconds|\n",
      "|  173.213.76.77|          43 seconds|\n",
      "|  109.74.154.79|          43 seconds|\n",
      "|   200.10.161.5|  1 hours 33 seconds|\n",
      "|    82.60.18.23|           1 seconds|\n",
      "+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "access_logs_df_gr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving apache log file parsed data\n",
    "access_logs_df.coalesce(1).write.format('csv').option(\"header\", \"true\").save('log_file_parsed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
